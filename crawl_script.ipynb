{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Driver set up\n",
    "\n",
    "## Browser settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_options = webdriver.EdgeOptions()\n",
    "# edge_options.add_argument('start-maximized')\n",
    "edge_options.add_argument('disable-extensions')\n",
    "edge_options.add_argument('ms:inPrivate')\n",
    "edge_options.add_argument('disable-infobars')\n",
    "edge_options.add_argument('inprivate')\n",
    "edge_options.add_argument('--disable-notifications')\n",
    "edge_options.add_argument('--enable-automation')\n",
    "edge_options.add_experimental_option(\"detach\", True)\n",
    "edge_options.add_argument(\"--disable-features=msEdgeEnableNurturingFramework\")\n",
    "edge_options.add_experimental_option(\"prefs\", {\"user_experience_metrics\": {\"personalization_data_consent_enabled\": True}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Secrets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_email = 'your_user_name'\n",
    "my_password = 'your_password'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize driver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Edge(keep_alive='./msedgedriver.exe', options=edge_options)\n",
    "driver.get('https://mbasic.facebook.com')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function\n",
    "\n",
    "## Parsing date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse post timestamp\n",
    "def parse_post_date(post):\n",
    "    timestamp_element = post.find('abbr')\n",
    "    timestamp_str = timestamp_element.text.strip()\n",
    "    # Convert Vietnamese month names to English for datetime parsing\n",
    "    month_map = {\n",
    "        'tháng 1': 'January', 'tháng 2': 'February', 'tháng 3': 'March',\n",
    "        'tháng 4': 'April', 'tháng 5': 'May', 'tháng 6': 'June',\n",
    "        'tháng 7': 'July', 'tháng 8': 'August', 'tháng 9': 'September',\n",
    "        'tháng 10': 'October', 'tháng 11': 'November', 'tháng 12': 'December'\n",
    "    }\n",
    "    for vietnamese, english in month_map.items():\n",
    "        timestamp_str = timestamp_str.replace(vietnamese, english)\n",
    "\n",
    "    timestamp_str = timestamp_str[0:timestamp_str.find('lúc')-1]\n",
    "    \n",
    "    post_date = datetime.strptime(timestamp_str, '%d %B')\n",
    "    return post_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See more post\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Function to click on \"Xem tin khác\" link if available\n",
    "def click_see_more_link():\n",
    "    try:\n",
    "        # Find the <a> tag containing the <span> with text \"Xem tin khác\"\n",
    "        see_more_link = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, \"//a[span[text()='Xem tin khác']]\")))\n",
    "        see_more_link.click()\n",
    "        time.sleep(2)  # Wait for posts to load\n",
    "    except NoSuchElementException:\n",
    "        print(\"No 'Xem tin khác' link found\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error clicking on 'Xem thêm' link: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reaction count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_react_list = ['https://scontent.fsgn5-10.fna.fbcdn.net/m1/v/t6/An-OY9MLHL-ZSjdewcBHqsUqbG_iKP7YPdv-VtLFuTjPb6JeVsW1ptvkRgGXI8lL3mIfyuCjIzzN5JF-_YVzwnU8ZKYcYb0PKaeIHGfC0HZDZMTjHQ.png?_nc_eui2=AeGpHRF1csrkKXGi14tWMJ8VvjDbL2sEdxq-MNsvawR3GhocIfjsr4KCCEhpavnwbnZfnQ_l-5uJBhT1XVQNRCMU&ccb=10-5&oh=00_AYCzLOj9WzFQ3yDmIHcYmAKTDb4b7vpBYyviGuFyMjFGGQ&oe=66A289AA&_nc_sid=7da55a', 'https://scontent.fsgn5-10.fna.fbcdn.net/m1/v/t6/An-6QMzYRPEP4s4LQEshZQ6Bx40DD5EIgaWfC5G5LQixNEFZf-hRWdy4--zN6aq5ZV-ry-7lMXUy7c9tyL_ZouBwtWg60RZ6s1A6ICUdO2-qJm1R.png?_nc_eui2=AeGdhxwh1SOsd-sFEx4lY0U3qciSfxI3tqOpyJJ_Eje2ox8_HW8fxUa08kIqyQBP630o5FZCPNJJtSZDkV1ISYaF&ccb=10-5&oh=00_AYCORDXA8-d1EXLff-YdFWSvFa8YZ7wkIVqtCJ7OkSfUxA&oe=66A282FE&_nc_sid=7da55a', 'https://scontent.fsgn5-10.fna.fbcdn.net/m1/v/t6/An-VBmEj0LPhn7r9Xz5guezTJlexmqlwQ-3VYyM27u4DWR7mpQVnzOLz67OONCtekVvQJcNDlQxkBMluKsBslk_OVGsOR14sE4Ws08M62Zieu5U.png?_nc_eui2=AeHpvc-ZZRXjSXNwIl9B1IJuvKB6rGfP5lC8oHqsZ8_mUOA_Wj6RW-Wna6SgVqZHGUTy0YIm2gUQFrQs2NrC0M_O&ccb=10-5&oh=00_AYAU6mbllxUctwhUrZ-T5tXpiYrhLo2x0TUlHNxJhPUKWg&oe=66A26581&_nc_sid=7da55a', 'https://scontent.fsgn5-10.fna.fbcdn.net/m1/v/t6/An9NamgJaDr3DddUsHGQ-envu3mt13Yo_osqqzTDZsaDqAup9-IzNhhOTMYkiqHYJHwCpwAuy7UWZlYUrLtp48435Lr-yNPScoTUkcxZkDKgdlVf.png?_nc_eui2=AeE-_5Al0Elz7b_rMJ-5nP6SIhlIWl90TrAiGUhaX3ROsMe7BEAw8Ln6iiJifOtL7gibdZrYUzWnVYVCszJn7a5M&ccb=10-5&oh=00_AYAc5I9U16Sh1QG5pLlkSg3xqxV4kqR3zrRoRpVwjgR6Lw&oe=66A27BC6&_nc_sid=7da55a', 'https://scontent.fsgn5-10.fna.fbcdn.net/m1/v/t6/An9ltC9_wCT7IwUJcodFBHhRbLYkvfoGweZkoXPe1V1EHIKN-qZQDxkIdv01AFtBOginaTV9YyHM-5WgTV0SFOQ10z32oD0llybf3laTMDTZXYpIvS02.png?_nc_eui2=AeEaCj3YRTEzq0vhUo7XKSbNlBpYHxmoj4WUGlgfGaiPhWDxN-xKyaWG7gNcDuwtVntH_CWbkzJ7nRDeXWNr2psG&ccb=10-5&oh=00_AYDVnhtP5LvY519badHMM36NX4F9_m_U9Bj6eD-bSPiWnw&oe=66A2624F&_nc_sid=7da55a', 'https://scontent.fsgn5-10.fna.fbcdn.net/m1/v/t6/An-B1pSuUzVYjvgsMKX_Vqj4-_lLytkM6Nozgd-KEQtGeI8Y9Dj67ingsy3_SeWpSSuVqtkvm86Rb2Nn5PDEyd2W0StC1YTvqRttUA4Ffuh_FPpP.png?_nc_eui2=AeFviAdyt8yDBjYRV4jLPeK-IP4eemdD7CYg_h56Z0PsJowSxVK9ax6kCuFXTpmnpcfcNn01PreB6bNAWkSP0tim&ccb=10-5&oh=00_AYAI7UrgLszeyfpcX4LQ6EZW1rRBj0xBjPyqR3_IAGxAWQ&oe=66A282FF&_nc_sid=7da55a', 'https://scontent.fsgn5-10.fna.fbcdn.net/m1/v/t6/An_awEcP5a-VJkiSKC4SklmLyo8p7Q3iP5vL6HDsa_ZTJdFfRRdtUFNJfr9LXPYfMhVSkFk4hqLRcj3zU9hTsyzpPGIc4jC3fiqwidCEo8AGZ4Rq.png?_nc_eui2=AeEUnQMs_BsOrH0ihfcpedXkgFb2z8QtW-iAVvbPxC1b6F1rLK8ZKzV7NDlgCR5PHdh0KjEBqisqSCPHpO-2BcZz&ccb=10-5&oh=00_AYC9w3V3YUiNJsn_4WJWS8YZVKDOT-9FD4U1mjAyaweTzA&oe=66A28512&_nc_sid=7da55a']\n",
    "\n",
    "def extract_reaction_count(post, src_list):\n",
    "    texts = []\n",
    "    top_react =[]\n",
    "    for img_tag in post.find_all('img'):\n",
    "        src = img_tag.get('src')\n",
    "        if src in src_list:\n",
    "            # Traverse up the parent tree to find <a> tag\n",
    "            parent = img_tag.parent\n",
    "            while parent:\n",
    "                if parent.name == 'a':\n",
    "                    texts.append(parent.get_text(strip=True).replace('.',''))\n",
    "                    break\n",
    "                parent = parent.parent\n",
    "        if src == src_list[0]:\n",
    "            top_react.append('Sad')\n",
    "        elif src == src_list[1]:\n",
    "            top_react.append('Heart')\n",
    "        elif src == src_list[2]:\n",
    "            top_react.append('Haha')\n",
    "        elif src == src_list[3]:\n",
    "            top_react.append('Wow')\n",
    "        elif src == src_list[4]:\n",
    "            top_react.append('Love')\n",
    "        elif src == src_list[5]:\n",
    "            top_react.append('Angry')\n",
    "        elif src == src_list[6]:\n",
    "            top_react.append('Like')\n",
    "    return texts, top_react"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_comment_count(post):\n",
    "    comment_count = 0\n",
    "    # Tìm tất cả các thẻ <a> trong bài post\n",
    "    a_tags = post.find_all('a')\n",
    "    # Duyệt qua từng thẻ <a> để tìm số lượng bình luận\n",
    "    for a_tag in a_tags:\n",
    "        # Lấy văn bản bên trong thẻ <a>\n",
    "        text = a_tag.get_text(strip=True)\n",
    "        # Kiểm tra xem văn bản có chứa từ \"bình luận\" không\n",
    "        if 'bình luận' in text:\n",
    "            # Trích xuất số lượng bình luận từ văn bản và chuyển đổi thành số nguyên\n",
    "            try:\n",
    "                comment_count = int(text.split()[0].replace('.', ''))\n",
    "                break  # Dừng khi đã tìm thấy số bình luận\n",
    "            except ValueError:\n",
    "                pass  # Bỏ qua nếu không thể chuyển đổi thành số nguyên\n",
    "    return comment_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crawling flow\n",
    "\n",
    "## Login\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login to Facebook\n",
    "username = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"input[name='email']\")))\n",
    "password = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"input[name='pass']\")))\n",
    "\n",
    "username.clear()\n",
    "username.send_keys(my_email)\n",
    "password.clear()\n",
    "password.send_keys(my_password)\n",
    "\n",
    "login_btn = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"input[type='submit']\"))).click()\n",
    "other_time_btn = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"a[class='bo bp bq br bt']\"))).click()\n",
    "\n",
    "driver.get('https://mbasic.facebook.com/TCCCVN/')\n",
    "timeline_btn = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"a[class='ct']\"))).click()\n",
    "\n",
    "click_see_more_link()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post 14 June\n",
      "['44']\n",
      "['Like']\n",
      "Post 14 June\n",
      "['1410', '1410']\n",
      "['Like', 'Heart']\n",
      "Post 12 June\n",
      "['156', '156', '156']\n",
      "['Like', 'Heart', 'Wow']\n",
      "Post 10 June\n",
      "['55']\n",
      "['Like']\n",
      "Post 08 June\n",
      "['102', '102']\n",
      "['Like', 'Heart']\n",
      "Post 08 June\n",
      "['84', '84', '84']\n",
      "['Like', 'Heart', 'Wow']\n",
      "Post 07 June\n",
      "['78', '78']\n",
      "['Like', 'Heart']\n",
      "Post 05 June\n",
      "['91', '91', '91']\n",
      "['Like', 'Heart', 'Wow']\n",
      "Post 29 May\n",
      "['148', '148']\n",
      "['Like', 'Heart']\n",
      "Post 28 May\n",
      "['80', '80']\n",
      "['Like', 'Heart']\n",
      "Post 27 May\n",
      "['8581', '8581']\n",
      "['Like', 'Heart']\n",
      "Post 24 May\n",
      "['88', '88', '88']\n",
      "['Like', 'Heart', 'Wow']\n",
      "Post 23 May\n",
      "['6474', '6474']\n",
      "['Like', 'Heart']\n",
      "Post 22 May\n",
      "['602', '602']\n",
      "['Like', 'Heart']\n",
      "Post 21 May\n",
      "['107', '107']\n",
      "['Like', 'Heart']\n",
      "Post 20 May\n",
      "['31', '31', '31']\n",
      "['Like', 'Heart', 'Wow']\n",
      "Post 14 May\n",
      "['165', '165', '165']\n",
      "['Like', 'Heart', 'Wow']\n",
      "Post 10 May\n",
      "['99', '99']\n",
      "['Like', 'Heart']\n",
      "Post 06 May\n",
      "['376', '376']\n",
      "['Like', 'Heart']\n",
      "Post 04 May\n",
      "['149', '149']\n",
      "['Like', 'Heart']\n",
      "Post 03 May\n",
      "['799', '799']\n",
      "['Like', 'Heart']\n",
      "Post 02 May\n",
      "['108', '108']\n",
      "['Like', 'Heart']\n",
      "Post 02 May\n",
      "['93', '93']\n",
      "['Like', 'Heart']\n",
      "Post 01 May\n",
      "['779', '779', '779']\n",
      "['Like', 'Heart', 'Wow']\n",
      "Post 26 April\n",
      "['48', '48', '48']\n",
      "['Like', 'Heart', 'Angry']\n",
      "Post 25 April\n",
      "['4177', '4177']\n",
      "['Like', 'Heart']\n",
      "Post 24 April\n",
      "['2898', '2898']\n",
      "['Like', 'Heart']\n",
      "Post 23 April\n",
      "['145', '145', '145']\n",
      "['Like', 'Heart', 'Angry']\n",
      "Post 23 April\n",
      "['30', '30', '30']\n",
      "['Like', 'Heart', 'Angry']\n",
      "Post 19 April\n",
      "['62635', '62635']\n",
      "['Like', 'Heart']\n",
      "Post 18 April\n",
      "['187', '187', '187']\n",
      "['Like', 'Heart', 'Wow']\n",
      "Post 18 April\n",
      "['275', '275', '275']\n",
      "['Like', 'Heart', 'Wow']\n",
      "Post 15 April\n",
      "['495', '495', '495']\n",
      "['Like', 'Heart', 'Sad']\n",
      "Post 15 April\n",
      "['78', '78']\n",
      "['Like', 'Heart']\n",
      "Post 13 April\n",
      "['1713', '1713']\n",
      "['Like', 'Heart']\n",
      "Post 07 April\n",
      "['60', '60', '60']\n",
      "['Like', 'Heart', 'Angry']\n",
      "Post 06 April\n",
      "['2336', '2336', '2336']\n",
      "['Like', 'Heart', 'Wow']\n",
      "Post 05 April\n",
      "['64', '64', '64']\n",
      "['Like', 'Heart', 'Angry']\n",
      "Post 03 April\n",
      "['1531', '1531']\n",
      "['Like', 'Heart']\n",
      "Post 01 April\n",
      "['1051', '1051']\n",
      "['Like', 'Heart']\n",
      "Post 27 March\n",
      "['312', '312', '312']\n",
      "['Like', 'Heart', 'Wow']\n",
      "Post 24 March\n",
      "['35', '35']\n",
      "['Like', 'Heart']\n",
      "Post 21 March\n",
      "['134', '134']\n",
      "['Like', 'Heart']\n",
      "Post 20 March\n",
      "['573', '573']\n",
      "['Like', 'Heart']\n",
      "Post 20 March\n",
      "['324', '324']\n",
      "['Like', 'Heart']\n",
      "Post 19 March\n",
      "['7673', '7673']\n",
      "['Like', 'Heart']\n",
      "Post 13 March\n",
      "['77', '77']\n",
      "['Like', 'Heart']\n",
      "Post 11 March\n",
      "['386', '386', '386']\n",
      "['Like', 'Heart', 'Sad']\n",
      "Post 08 March\n",
      "['736', '736', '736']\n",
      "['Like', 'Heart', 'Wow']\n",
      "Post 03 March\n",
      "['85', '85', '85']\n",
      "['Like', 'Heart', 'Sad']\n",
      "Post 01 March\n",
      "['3227', '3227', '3227']\n",
      "['Like', 'Heart', 'Wow']\n",
      "Post 01 March\n",
      "['111', '111', '111']\n",
      "['Like', 'Heart', 'Wow']\n",
      "Post 23 February\n",
      "['53', '53', '53']\n",
      "['Like', 'Heart', 'Wow']\n",
      "Post 19 February\n",
      "['52', '52']\n",
      "['Like', 'Heart']\n",
      "Post 12 February\n",
      "['617', '617']\n",
      "['Like', 'Heart']\n",
      "Post 10 February\n",
      "['2136', '2136']\n",
      "['Like', 'Heart']\n",
      "Post 08 February\n",
      "['61', '61']\n",
      "['Like', 'Heart']\n",
      "Post 05 February\n",
      "['66', '66']\n",
      "['Like', 'Heart']\n",
      "Post 02 February\n",
      "['12240', '12240']\n",
      "['Like', 'Heart']\n"
     ]
    }
   ],
   "source": [
    "found_end_post = False\n",
    "post_content = []\n",
    "data = []\n",
    "\n",
    "# List of possible class names for posts\n",
    "post_classes = ['bm bn bo', 'bn bo bp']\n",
    "\n",
    "while not found_end_post:\n",
    "    html_content = driver.page_source\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    posts_found = False\n",
    "\n",
    "    # Try to find posts using each class name in the list\n",
    "    for post_class in post_classes:\n",
    "        posts = soup.find_all('div', class_=post_class)\n",
    "        if posts:\n",
    "            for post in posts:\n",
    "                timestamp = parse_post_date(post)\n",
    "                if timestamp:\n",
    "                    if timestamp.month <= 1:  # Stop if the post is from March or earlier\n",
    "                        found_end_post = True\n",
    "                        break\n",
    "                    \n",
    "                    # Extract paragraphs from each post\n",
    "                    paragraphs_list = []\n",
    "                    paragraphs = post.find_all('p')\n",
    "                    for p in paragraphs:\n",
    "                        paragraph_text = p.get_text(strip=True)\n",
    "                        paragraphs_list.append(paragraph_text)\n",
    "                    \n",
    "                    post_content.append(paragraphs_list)\n",
    "                    react, top_react = extract_reaction_count(post, src_react_list)\n",
    "                    comment_count = extract_comment_count(post)\n",
    "                    # Append data to list for dataframe\n",
    "                    data.append({'date': timestamp.strftime('%d %B'), 'content': paragraphs_list, 'reaction_count': react, 'top_react': top_react, 'comment_count': comment_count})\n",
    "                    \n",
    "                    print('Post' + \" \" + timestamp.strftime('%d %B'))\n",
    "                    print(react)\n",
    "                    print(top_react)\n",
    "                    # print(timestamp.strftime('%d %B'))\n",
    "                    # print(paragraphs_list)\n",
    "                    # print('-' * 50)\n",
    "                    \n",
    "                    posts_found = True  # Indicate that posts were found\n",
    "            \n",
    "            if found_end_post:\n",
    "                break\n",
    "\n",
    "    if not posts_found:\n",
    "        print(\"No more posts found matching the criteria.\")\n",
    "        break\n",
    "\n",
    "    if not found_end_post:\n",
    "        click_see_more_link()\n",
    "\n",
    "# # Close the WebDriver\n",
    "# driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the list of dictionaries\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Change date format to 'dd/mm'\n",
    "df['date'] = pd.to_datetime(df['date'], format='%d %B')\n",
    "df = df[df['date'].dt.month < 5]\n",
    "# df['date'] = df['date'].dt.strftime('%d/%m')\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "# df = df.drop_duplicates(subset='date', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store titles\n",
    "titles = []\n",
    "\n",
    "# Iterate through each row in 'content' column\n",
    "for content in df['content']:\n",
    "    # Get the first element of the list (assuming 'content' is a list of strings)\n",
    "    title = content[0] if isinstance(content, list) and len(content) > 0 else None\n",
    "    titles.append(title)\n",
    "\n",
    "# Assign the list of titles to a new column 'title' in the dataframe\n",
    "df['title'] = titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sắp xếp lại DataFrame theo thứ tự giảm dần của date\n",
    "df = df.sort_values(by='date', ascending=True).reset_index(drop=True)\n",
    "\n",
    "# Tính khoảng cách giữa các ngày\n",
    "df['day_diff'] = df['date'].diff().dt.days\n",
    "\n",
    "df['date'] = df['date'].dt.strftime('%d/%m')\n",
    "\n",
    "# Chuyển đổi danh sách các số thành các giá trị dạng số\n",
    "df['reaction_count'] = df['reaction_count'].apply(lambda x: list(map(int, x)))\n",
    "\n",
    "# Giữ lại các giá trị duy nhất trong từng danh sách\n",
    "df['reaction_count'] = df['reaction_count'].apply(set)\n",
    "\n",
    "# Chuyển đổi set thành danh sách hoặc lấy giá trị đầu tiên\n",
    "df['reaction_count'] = df['reaction_count'].apply(lambda x: next(iter(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('coke_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
